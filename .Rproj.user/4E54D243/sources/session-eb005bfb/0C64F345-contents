---
title: 'Exploring the Research Landscape on Single-Case Design Methodology Using Technology Through Text Mining and Large Language Models'
# logo: ''
date: "`r Sys.Date()`"
code-annotations: hover
sidebar: false
toc: true
format: 
  html:
    code-fold: true
    code-tools: true
    highlight: tango
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{=html}
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  
  <style>
  .responsive-figure {
    width: 100% !important;
    height: auto;
  }

.hover-effect:hover {
  color: #2B6CB0 !important;
    transition: color 0.3s ease;
}

.responsive-iframe {
  width: 100% !important;
  height: auto;
  min-height: 400px;
  max-width: 100%;
}

.responsive-table {
  width: 100% !important;
  overflow-x: auto;
  display: block;
}

.iframe-container {
  position: relative;
  width: 100%;
  padding-bottom: 56.25%; /* 16:9 Aspect Ratio */
    height: 0;
  overflow: hidden;
}

.iframe-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border: 0;
}

@media (max-width: 768px) {
  .responsive-iframe {
    min-height: 300px;
  }
  .iframe-container {
    padding-bottom: 75%; /* 4:3 Aspect Ratio for smaller screens */
  }
}

@media (max-width: 480px) {
  .responsive-iframe {
    min-height: 200px;
  }
  .iframe-container {
    padding-bottom: 100%; /* 1:1 Aspect Ratio for mobile */
  }
}
</style>
```

# Screening

Figure 1. Semi-Automated AI-Driven Publication Screening

![](files/screening_procedure.png)

### Extract Web of Science (WoS) Data

```{r}
#| code-fold: false
suppressPackageStartupMessages({
  library(tidyverse)
  library(knitr)
  library(readxl)
  library(data.table)
  library(DT)
  library(bibliometrix)
  library(plyr)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
  library(stringr)
  library(openxlsx)
  library(sf)
  library(rnaturalearth)
  library(ggrepel)
  library(ggiraph)
  library(stringi)
  library(brms)
})

load("evolution/bayes_model.RData")
```

### Import Wos Data

```{r, eval=FALSE}
wos_1_500 <- convert2df("1_500.ciw", dbsource = "wos", format = "endnote")
wos_501_1000 <- convert2df("501_1000.ciw", dbsource = "wos", format = "endnote")
wos_1001_1500 <- convert2df("1001_1500.ciw", dbsource = "wos", format = "endnote")
wos_1501_2000 <- convert2df("1501_2000.ciw", dbsource = "wos", format = "endnote")
wos_2001_2500 <- convert2df("2001_2500.ciw", dbsource = "wos", format = "endnote")
wos_2501_3000 <- convert2df("2501_3000.ciw", dbsource = "wos", format = "endnote")
wos_3001_3500 <- convert2df("3001_3500.ciw", dbsource = "wos", format = "endnote")
wos_3501_4000 <- convert2df("3501_4000.ciw", dbsource = "wos", format = "endnote")
wos_4001_4500 <- convert2df("4001_4500.ciw", dbsource = "wos", format = "endnote")
wos_4501_5000 <- convert2df("4501_5000.ciw", dbsource = "wos", format = "endnote")
wos_5001_5500 <- convert2df("5001_5500.ciw", dbsource = "wos", format = "endnote")
wos_5501_5935 <- convert2df("5501_5935.ciw", dbsource = "wos", format = "endnote")
```

### Bind Rows and Filter Publications

```{r, eval=FALSE}
wos_5935 <- rbind.fill(wos_1_500,
                       wos_501_1000,
                       wos_1001_1500,
                       wos_1501_2000,
                       wos_2001_2500,
                       wos_2501_3000,
                       wos_3001_3500,
                       wos_3501_4000,
                       wos_4001_4500,
                       wos_4501_5000,
                       wos_5001_5500,
                       wos_5501_5935)

wos <- wos_5935 %>% 
  filter(PY >= 1970)

write.csv(wos, "init_all_data.csv", row.names = FALSE)
```

### Fine-Tuning for Publication Classification Tasks

#### `Step 1. Text classification for using single case design`

[<i class="fas fa-code"></i> Code](single_case/index.html){style="color: #6D6D6D; text-decoration: none;" .hover-effect} | Figure 2 (A). Single Case Design Classification 

![](files/single-case-results.png)

#### `Step 2. Text classification for using technology`

[<i class="fas fa-code"></i> Code](technology_use/index.html){style="color: #6D6D6D; text-decoration: none;" .hover-effect} | Figure 2 (B). Technology Use Classification 

![](files/technology-use-results.png)

#### `Step 3. Filtering studies including methodology content` 

[<i class="fas fa-code"></i> Code](methodology/index.html){style="color: #6D6D6D; text-decoration: none;" .hover-effect}

Employed a list of **77 wild expressions**, composed with **regular expressions** to process the data.

# Bibliometrics

### Main Findings

```{r, eval=FALSE}
data <- read.xlsx("../data/df.xlsx")

data <- data %>% filter(data$filtered == "Yes")

data_descriptive <- data %>%
  dplyr::mutate(Study = paste("study", row_number(), sep = "")) %>%
  dplyr::mutate(document = paste(Study, PY, sep = "_")) %>%
  ungroup()

data_descriptive <- data_descriptive %>%
  dplyr::select(document, everything())

data_descriptive$DT <- case_when(
  data_descriptive$DT == "ARTICLE" ~ "Article",
  data_descriptive$DT == "BOOK CHAPTER" ~ "Book Chapter",
  data_descriptive$DT == "ARTICLE; BOOK CHAPTER" ~ "Book Chapter",
  data_descriptive$DT == "REVIEW; BOOK CHAPTER" ~ "Book Chapter",
  data_descriptive$DT == "ARTICLE; DATA PAPER" ~ "Article",
  data_descriptive$DT == "EARLY ACCESS" ~ "Early Access",
  data_descriptive$DT == "ARTICLE; EARLY ACCESS" ~ "Article",
  data_descriptive$DT == "REVIEW; EARLY ACCESS" ~ "Review",
  data_descriptive$DT == "PROCEEDINGS PAPER" ~ "Proceeding Paper",
  data_descriptive$DT == "ARTICLE; PROCEEDINGS PAPER" ~ "Article",
  data_descriptive$DT == "REVIEW" ~ "Review",
  data_descriptive$DT == "EDITORIAL MATERIAL" ~ "Editorial Material",
  data_descriptive$DT == "MEETING ABSTRACT" ~ "Meeting Abstract",
  TRUE ~ as.character(data_descriptive$DT)
)

source_hindex <- bibliometrix::Hindex(data_descriptive, years = Inf, field = "source")$H
source_hindex$SO <- source_hindex$Element
source_hindex$m_index <- round(source_hindex$m_index, 2)

source_TC <- data_descriptive %>%
  dplyr::group_by(SO) %>%
  dplyr::summarize(total_citation = sum(TC)) %>%
  dplyr::mutate(total_citation_percent = round((total_citation / sum(total_citation) * 100),2)) %>%
  ungroup()

source_TP <- data_descriptive %>%
  dplyr::group_by(SO) %>%
  dplyr::summarize(publication_number = n()) %>%
  dplyr::mutate(publication_number_percent = round((publication_number / sum(publication_number) * 100),2)) %>%
  ungroup()

source_detail <- left_join(source_TC, source_TP, by = "SO")

source_detail <- source_detail %>%
  group_by(SO) %>%
  dplyr::mutate(citation_per_publication = round((total_citation / publication_number),0))

source_detail <- source_detail %>% arrange(desc(total_citation), desc(publication_number))
source_combined <- left_join(source_detail, source_hindex, by = "SO")
source_combined <- source_combined %>%
  arrange(desc(total_citation), desc(publication_number)) %>%
  select(SO, PY_start, publication_number, publication_number_percent,
         total_citation, total_citation_percent,
         citation_per_publication,
         h_index, g_index, m_index)


write.xlsx(source_combined, file = "files/source_combined.xlsx", colNames = TRUE)

results <- biblioAnalysis(data_descriptive)
descriptive_summary <- summary(results, k=71, pause=F, width=130)
MainInformationDF <- descriptive_summary$MainInformationDF

write.xlsx(MainInformationDF, file = "files/MainInformationDF.xlsx", colNames = TRUE)

MostProdCountries <- descriptive_summary$MostProdCountries

write.xlsx(MostProdCountries, file = "files/MostProdCountries.xlsx", colNames = TRUE)

TCperCountries <- descriptive_summary$TCperCountries

write.xlsx(TCperCountries, file = "files/TCperCountries.xlsx", colNames = TRUE)
```

```{r, echo=FALSE}
MainInformationDF <- read_excel("files/MainInformationDF.xlsx")

DT::datatable(
  MainInformationDF,
  options = list(
    dom = 'Bfrtip',
    buttons = c('copy', 'csv', 'excel', 'pdf'),
    pageLength = 10,
    scrollX = TRUE
  ),
  extensions = 'Buttons',
  class = "cell-border stripe",
  rownames = FALSE
) 
```

# World Map

### Map Publications and Citations Across Countries

```{r, eval=FALSE}
MostProdCountries <- MostProdCountries %>%
  mutate(
    Articles = as.numeric(Articles),
    Freq = as.numeric(Freq),
    SCP = as.numeric(SCP),
    MCP = as.numeric(MCP),
    MCP_Ratio = as.numeric(MCP_Ratio)
  )

TCperCountries <- TCperCountries %>%
  mutate(
    `Total Citations` = as.numeric(`Total Citations`),
    `Average Article Citations` = as.numeric(`Average Article Citations`)
  )

colnames(TCperCountries) <- stringr::str_trim(colnames(TCperCountries))

Countries_Prod_TC <- MostProdCountries %>%
  left_join(TCperCountries, by = "Country")

Countries_Prod_TC <- Countries_Prod_TC %>%
  mutate(Country = str_trim(Country, "both") %>% str_to_title())

Countries_Prod_TC <- Countries_Prod_TC %>%
  mutate(Country = case_when(
    Country == "Usa" ~ "USA",
    Country == "Korea" ~ "South Korea",
    Country == "U Arab Emirates" ~ "UAE",
    Country == "United Kingdom" ~ "UK",
    TRUE ~ as.character(Country)
  ))

write.xlsx(Countries_Prod_TC, file = "files/Countries_Prod_TC.xlsx", colNames = TRUE)

sf::sf_use_s2(TRUE)

world <- ne_countries(scale = "small", returnclass = "sf")

world <- world %>%
  mutate(admin = case_when(
    admin == "United States of America" ~ "USA",
    admin == "United Arab Emirates" ~ "UAE",
    admin == "United Kingdom" ~ "UK",
    admin == "United Republic of Tanzania" ~ "Tanzania",
    admin == "Republic of Serbia" ~ "Serbia",
    TRUE ~ as.character(admin)
  ))

wintr_proj <- "+proj=wintri +datum=WGS84 +no_defs +over"

if (is.na(st_crs(world))) {
  st_crs(world) <- 4326
}

world_projected <- lwgeom::st_transform_proj(world, crs = wintr_proj)
centroids_projected <- st_centroid(st_geometry(world_projected))
centroids_geo <- st_transform(centroids_projected, crs = st_crs(world))
world_centroids <- cbind(world, st_coordinates(centroids_geo))
world_joined <- left_join(world, Countries_Prod_TC, by = c("admin" = "Country"))
world_joined_filtered <- world_joined %>% filter(!is.na(Articles))
world_joined_filtered <- world_joined_filtered %>%
  mutate(country_article = paste(admin, Articles))

world_sf <- st_as_sf(world_joined_filtered, coords = c("longitude", "latitude"), crs = "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")

b <- c(200, 2000, 5000, 10000, 20000, 40000, 60000, 70000)

# Create the world map with centroids and labels
world_map_init <- world_sf %>%
  ggplot() +
  geom_sf_interactive(aes(fill = `Total Citations`,
                          tooltip = paste("TC: ", admin, `Total Citations`)),
                      size = 0.25) +
  geom_label_repel(
    size = 3.3,
    aes(geometry = geometry, label = admin),
    alpha = 0.7,
    max.overlaps = 13,
    stat = "sf_coordinates"
  ) +
  scale_fill_viridis_c(trans = "sqrt", na.value = "white", breaks = b, direction = -1, alpha = 0.9, begin = 0.6, end = 1) +
  geom_point_interactive(
    aes(size = Articles,
        geometry = geometry,
        tooltip = paste("TP: ", admin, Articles)),
    stat = "sf_coordinates",
    stroke = 1,
    shape = 21,
    color = "#A84268",
    alpha = 0.6
  ) +
  theme_void() +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal",
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 10)
  ) +
  labs(fill = "Total citations (TC)", size = "Total publications (TP)") +
  guides(
    fill = guide_colourbar(title.position = "top", title.hjust = 0.5, barwidth = 18, barheight = 1),
    size = guide_legend(title.position = "top", title.hjust = 0.5)
  )

world_map <- girafe(ggobj = world_map_init, width_svg = 10, height_svg = 5) %>%
  girafe_options(
    opts_hover(css = "fill:cyan;"),
    opts_sizing(rescale = TRUE),
    css = "div.girafe-container { padding-top: 0px; margin-top: -20px; }
           .ggiraph-toolbar { position: absolute; bottom: 10px; right: 10px; }"
  )

htmlwidgets::saveWidget(
  widget = world_map,
  file = "world_map/index.html",
  selfcontained = TRUE)

ggsave('files/world_map.png',
       width = 7, height = 3.5, dpi = 300, plot = world_map_init)

save(world_map, file = "files/world_map.RData")
```

```{r, echo=FALSE}
load("files/world_map.RData")
world_map
```

# Topic Modeling

[<i class="fas fa-code"></i> Code](topic_modeling/index.html){style="color: #6D6D6D; text-decoration: none;" .hover-effect} | 
  [Figure 4](topic_modeling/docs_topics.html){style="color: #6D6D6D; text-decoration: none;" .hover-effect} | 
  [Figure 5](topic_modeling/fig_cosine_sim.html){style="color: #6D6D6D; text-decoration: none;" .hover-effect}

<div class="iframe-container" style="width: 100%; max-width: 800px; height: 800px; margin: 0 auto;">
<iframe src="topic_modeling/docs_topics.html" style="width: 100%; height: 100%; border: none;"></iframe>
</div>

<div class="iframe-container" style="width: 100%; max-width: 800px; height: 800px; margin: 0 auto;">
<iframe src="topic_modeling/fig_cosine_sim.html" style="width: 100%; height: 100%; border: none;"></iframe>
</div>
  
# Evolution of Research
  
### Word Co-Occurrence Network Analysis 
  
[<i class="fas fa-project-diagram"></i> Web APP](https://mkshin.shinyapps.io/scd_network/){style="color: #6D6D6D; text-decoration: none;" .hover-effect}  
  
<div class="iframe-container" style="width: 100%; max-width: 800px; height: 800px; margin: 0 auto;">
<iframe src="https://mkshin.shinyapps.io/scd_network/" style="width: 100%; height: 100%; border: none;"></iframe>
</div>
  
```{r, echo=FALSE}
new_word_count_df <- read_excel("evolution/new_word_count_df.xlsx")
```

### Bayesian Negative Binomial Piecewise Regression

[<i class="fas fa-code"></i> Code](evolution/index.html){style="color: #6D6D6D; text-decoration: none;" .hover-effect} | 
  [Figure 6](evolution/new_word_plot.html){style="color: #6D6D6D; text-decoration: none;" .hover-effect}

#### Changes in New Word Counts

```{r, echo=FALSE, eval=FALSE}
new_word_gg <- new_word_count_df %>% 
  ggplot(aes(x = Year, y = Count, group = Topic)) +
  geom_line(linewidth = 0.3, alpha = 0.3) +
  geom_point(size = 0.7, alpha = 0.7) +
  labs(x = "Year", y = "New Word Count") +
  facet_wrap(~ Topic, ncol = 3, scales = "free_y",
             labeller = labeller(Topic = function(x) paste("Topic", x))) +
  scale_x_continuous(
      breaks = seq(1970, 2020, by = 20),
      limits = c(1970, 2025),
      expand = expansion(0, 0)
  ) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid.minor   = element_blank(),
    panel.grid.major.x = element_line(color = "gray90"),
    panel.grid.major.y = element_line(color = "gray90"),
    strip.text         = element_text(size = 12),
    axis.line.x        = element_line(color = "gray90"),
    axis.line.y        = element_line(color = "gray90"),
    axis.ticks.length  = unit(0.2, "cm"),
     axis.text.x        = element_text(size = 12),
    axis.text.y        = element_text(size = 12),
    axis.title.x       = element_text(
                           size   = 12, 
                           margin = margin(t = 5)   
                         ),
    axis.title.y       = element_text(
                           size   = 12, 
                           margin = margin(r = 12),  
                           angle  = 90, 
                           vjust  = 0.5
                         ),

    legend.title       = element_text(size = 12, hjust = 0.5),
    legend.text        = element_text(size = 12),
    legend.position    = "bottom",

    plot.margin        = margin(t = 10, r = 10, b = 40, l = 40)
  )

new_word_plot <- plotly::ggplotly(new_word_gg, width = 800, height = 800) %>% 
  plotly::layout(
    margin = list(t = 40, b = 80, l = 80, r = 20),   
    legend = list(
      orientation = "h",
      x           = 0.5,
      xanchor     = "center",
      y           = -0.1
    )
  )

suppressWarnings(htmlwidgets::saveWidget(
  widget = new_word_plot %>% 
    plotly::layout(
      autosize = TRUE,
      margin = list(t = 40, b = 80, l = 80, r = 20),
      legend = list(
        orientation = "h",
        x = 0.5,
        xanchor = "center",
        y = -0.1
      )
    ), 
  file = "evolution/new_word_plot.html",
  selfcontained = TRUE))
```

<div class="iframe-container" style="width: 100%; max-width: 800px; height: 800px; margin: 0 auto;">
<iframe src="evolution/new_word_plot.html" style="width: 100%; height: 100%; border: none;"></iframe>
</div>

#### Summary Statistics

```{r}
summary(new_word_count_df$Count)
```

#### Dispersion Ratio

```{r}
mean_val <- mean(new_word_count_df$Count)
var_val  <- var(new_word_count_df$Count)
overdispersion_ratio <- var_val / mean_val
overdispersion_ratio
```

#### Preprocess

```{r, eval=FALSE}
#| code-fold: false
new_word_count_data <- new_word_count_df %>%
  group_by(Topic) %>%
  dplyr::mutate(
    init_year = min(Year, na.rm = TRUE)) %>%
  ungroup()

new_word_count_data <- new_word_count_data %>%
  group_by(Topic) %>%
  dplyr::mutate(year_init_c = Year - first(na.omit(init_year))) %>%
  dplyr::mutate(jump_2010 = as.integer(I(Year >= 2010))) %>%
  dplyr::mutate(slope_2010 = (Year - 2010)*jump_2010) %>%
  select(-init_year)
```

#### Estimate the Model

```{r, eval=FALSE}
#| code-fold: false

new_word_count_data$Topic <- as.factor(new_word_count_data$Topic)
new_word_count_data$Topic <- relevel(new_word_count_data$Topic, ref = "2")

formula_new_word <- bf(
  Count ~ 1 + year_init_c + jump_2010 + slope_2010 +
    Topic + year_init_c*Topic + jump_2010*Topic + slope_2010*Topic 
)

model_new_word <- brm(
  formula = formula_new_word,
  data = new_word_count_data,
  family = negbinomial(link = "log"),
  control = list(adapt_delta = 0.95, max_treedepth = 12),
  iter = 2000,
  warmup = 1000,
  cores = 4, 
  chains = 1,
  seed = 2025
)
```

```{r, echo=FALSE, eval=FALSE}
#| code-fold: false
prior_summary(model_new_word)
```

```{r, echo=FALSE, eval=FALSE}
#| code-fold: false
summary(model_new_word)
```

```{r, eval=FALSE, echo=FALSE}
coefs <- fixef(model_new_word)
coefs_df <- data.frame(
  Variable = rownames(coefs),
  Estimate = coefs[,"Estimate"], 
  Est.Error  = coefs[, "Est.Error"], 
  Q2.5 = coefs[,"Q2.5"], 
  Q97.5 = coefs[,"Q97.5"],
  stringsAsFactors = FALSE
)

irr_df <- data.frame(
  Variable   = rownames(coefs),
  IRR     = exp(coefs[,"Estimate"]),  
  Q2.5 = exp(coefs[,"Q2.5"]), 
  Q97.5 = exp(coefs[,"Q97.5"]), 
  stringsAsFactors = FALSE
)

model_new_word_results <- merge(coefs_df, irr_df, by = "Variable") %>% 
  mutate_if(is.numeric, ~ round(., 3))

names(model_new_word_results) <- c("Variable",
                                   "Estimate",
                                   "Est.Error",
                                   "Q2.5",
                                   "Q97.5",
                                   "IRR",
                                   "Q2.5",
                                   "Q97.5")
```

```{r, echo=FALSE}
# knitr::kable(model_new_word_results, row.names = FALSE)

DT::datatable(
  model_new_word_results,
  options = list(
    dom = 'Bfrtip',
    buttons = c('copy', 'csv', 'excel', 'pdf'),
    pageLength = 10,
    scrollX = TRUE
  ),
  extensions = 'Buttons',
  class = "cell-border stripe",
  rownames = FALSE
) 
```

#### Posterior Predictive Checks

```{r, echo=FALSE}
#| code-fold: false
pp_check(model_new_word)
```

```{r, echo=FALSE, eval=FALSE}
#| code-fold: false
# Posterior Density Plots and Trace Plots
plot(model_new_word)
```

```{r, echo=FALSE, eval=FALSE}
#| code-fold: false
mcmc_plot(model_new_word, type = "trace")
```

```{r, echo=FALSE, eval=FALSE}
save(new_word_count_df, new_word_plot, model_new_word, model_new_word_results, file = "evolution/bayes_model.RData")
```
