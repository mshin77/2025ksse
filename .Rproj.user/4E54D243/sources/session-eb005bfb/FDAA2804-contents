---
author:
  - name: Mikyung Shin (신미경)
    affiliation: Illinois State University
    email: mshin2@ilstu.edu
    orcid: https://orcid.org/0000-0001-7907-9193
format: 
  revealjs:
    theme: ["theme/ppt-theme.scss"]
    transition: slide
    transition-speed: fast
    slide-number: c/t
    logo: ""
    code-copy: true
    center-title-slide: false
    chalkboard: 
      buttons: true
    code-fold: true
    code-overflow: scroll
    code-link: true
    highlight-style: a11y
    touch: true
    controls: true
    hash-type: number
    hash-one-based-index: true
    slide-tone: false
linestretch: 1.5
width: 1024 
height: 768
execute: 
  eval: true
  echo: true
editor: 
  markdown: 
    wrap: 72
---

<br><br>

<h1>시각적 분석 및 베이지안 다층 모형: 학습장애 학생을 위한 단일대상설계
연구</h1>

<h4>신미경 (Illinois State University 조교수) 박지연 (Eastern Kentucky
University 부교수)</h4>

<br>

<h1>Visual Analysis and Bayesian Multilevel Models: Single-Case Design
Research for Students with Learning Disabilities</h1>

<h4>Mikyung Shin (Assistant Professor, Dept. of Special Education)
Jiyeon Park (Associate Professor, Dept. of Teaching, Learning, and
Educational Leadership)</h4>

<h4>`r fontawesome::fa("github", "#233150")`  
[github.com/mshin77/2025ksse](https://github.com/mshin77/2025ksse)  
`r fontawesome::fa("home", "#233150")`  
[mshin77.net](https://mshin77.net)</h4>

::: footer
2025 한국특수교육학회 하계학술대회 발표 2025.6.28.
:::

## `목차`

```{r}
# Set up

load("data/2025ksse_data.RData")

suppressPackageStartupMessages({
    library(readxl)
    library(readr)
    library(kableExtra)
    library(plotly)
    library(ggplot2)
    library(dplyr)
    library(tidyr)
    library(nlme)
    library(scdhlm)
    library(sjPlot)
    library(quanteda)
    library(TextAnalysisR)
    library(spacyr)
    library(stringr)
    library(widyr)
    library(tidygraph)
    library(visNetwork)
    library(RColorBrewer)
    library(htmltools)
})

htmltools::tags$style(HTML("
  div.dataTables_info, 
  div.dataTables_paginate, 
  .dataTables_length, 
  .dataTables_filter {
    font-size: 20px !important;
  }
  .dataTables_paginate ul.pagination {
    flex-wrap: nowrap !important;
    white-space: nowrap !important;
  }
"))
```


::::: columns
::: {.column width="70%"}
-   학습장애 학생 대상 단일대상 실험설계 동향 <br>
-   시각적 분석 특성 <br>
-   다층 종단 모형 분석 특성 <br>
-   학습장애 학생 수학 중재 연구
- 시각적 분석 연구 결과
- 베이지안 다층 모형 연구결과
:::

::: {.column width="30%"}
![](data/qr.png){fig-align="center" width="209"}
:::
:::::

## `단일대상 실험설계 동향`

```{r, eval= FALSE}
df <- read_excel("data/wos.xlsx")

year_doc <- df %>%
  dplyr::select(PY, UT) %>%
  group_by(PY) %>%
  dplyr::summarize(publication_number = n()) 

year_plot <- year_doc %>%
  ggplot() +
  geom_col(aes(PY, publication_number), fill = "#B3B3B3") +
  labs(x = "", y = "논문 수") +
  theme_classic(base_size = 14) +
  theme(
    axis.line           = element_line(color = "#404040", linewidth =  0.2),
    axis.title.y.left   = element_text(size = 16, color = "#404040", margin = margin(r = 10)),
    axis.text.y.left    = element_text(size = 16, margin = margin(l = 7)),
    axis.text.x         = element_text(size = 14)
  ) +
  annotate("text", 
           x = min(year_doc$PY) + (max(year_doc$PY) - min(year_doc$PY))/2.5,
           y = max(year_doc$publication_number) * 0.9,
           label = "데이터베이스: Web of Science, 1970-2025\n총 3,508편 (단일대상: \"single* case* design\" 등 18개 검색어)\nAND (공학: \"technolog*\" 등 49개 검색어)",
           hjust = 0,
           size = 6,
           color = "#404040") +
  annotate("text",
           x = max(year_doc$PY) - 7,
           y = -12,
           label = "(Shin & McKenna, 2025) 자료",
           hjust = 1,
           vjust = 0,
           size = 4,
           color = "#404040")

year_plotly <- year_plot %>% plotly::ggplotly() 
```

```{r, echo = FALSE}
year_plotly
```

## `1971년-2009년 학습장애 학생 단일대상 실험설계 동향`

::::: columns
::: {.column width="60%"}

```{r, echo=FALSE, results='asis', eval=FALSE}
# 단어 네트워크 분석에 필요한 함수 정의
word_correlation_network <- function(dfm_object,
                                     doc_var = NULL,
                                     common_term_n = 130,
                                     corr_n = 0.4,
                                     top_node_n = 40,
                                     node_label = 50,
                                     nrows = 1,
                                     height = 1000,
                                     width = 900,
                                     pattern = NULL,
                                     showlegend = TRUE,
                                     seed = NULL) {
    
    dfm_td <- tidytext::tidy(dfm_object)
    docvars_df <- dfm_object@docvars
    docvars_df$document <- docvars_df$docname_
    dfm_td <- dplyr::left_join(dfm_td, docvars_df, by = "document")
    
    if (!is.null(doc_var) && doc_var != "" && !doc_var %in% colnames(dfm_td)) {
        message("Document-level metadata variable '", doc_var, "' was not selected or not found.")
        doc_var <- NULL
    }
    
    if (!is.null(doc_var) && doc_var %in% colnames(dfm_td)) {
        docvar_levels <- unique(dfm_td[[doc_var]])
        print(paste("doc_var has", length(docvar_levels), "levels:", paste(docvar_levels, collapse = ", ")))
    } else {
        docvar_levels <- NULL
    }
    
    build_table <- function(net) {
        layout_dff <- net$layout_df %>% dplyr::mutate_if(is.numeric, round, digits = 3)
        
        DT::datatable(
            layout_dff,
            rownames   = FALSE,
            extensions = 'Buttons',
            options    = list(
                scrollX        = TRUE,
                width          = "80%",
                dom            = 'Bfrtip',
                pageLength     = 10,
                buttons        = "",
                pagingType     = "full",
                headerCallback = htmlwidgets::JS(
                    "function(thead, data, start, end, display){",
                    "  $(thead).find('th').css({",
                    "    'font-size': '20px', ",
                    "    'padding': '4px 8px'",
                    "  });",
                    "}"
                )
            )
        ) %>%
            DT::formatStyle(
                columns   = colnames(layout_dff),
                fontSize  = "20px"           
            ) %>%
            htmltools::tagList()
}
    
    build_network_plot <- function(data, group_level = NULL) {
        if (!is.null(seed)) set.seed(seed)
        term_cor <- data %>%
            group_by(term) %>%
            filter(n() >= common_term_n) %>%
            widyr::pairwise_cor(term, document, sort = TRUE) %>%
            dplyr::ungroup() %>%
            dplyr::filter(correlation > corr_n)
        
        if (!is.null(pattern)) {
            term_cor <- term_cor %>%
                dplyr::filter(grepl(pattern, item1, ignore.case = TRUE) | grepl(pattern, item2, ignore.case = TRUE))
        }
        
        graph <- igraph::graph_from_data_frame(term_cor, directed = FALSE)
        if(igraph::vcount(graph) == 0) {
            message("No correlation relationships meet the threshold.")
            return(NULL)
        }
        igraph::V(graph)$degree      <- igraph::degree(graph)
        igraph::V(graph)$eigenvector <- igraph::eigen_centrality(graph)$vector
        igraph::V(graph)$community   <- igraph::cluster_leiden(graph)$membership
        
        layout_df <- data.frame(
            단어 = igraph::V(graph)$name,
            연결 = igraph::V(graph)$degree,
            고유벡터 = igraph::V(graph)$eigenvector
            # 커뮤니티 = igraph::V(graph)$community
        )
        
        node_degrees <- igraph::degree(graph)
        sorted_indices <- order(node_degrees, decreasing = TRUE)
        top_n <- min(top_node_n, length(sorted_indices))
        top_nodes <- names(node_degrees)[sorted_indices[1:top_n]]
        
        nodes <- data.frame(
            id = igraph::V(graph)$name,
            label = ifelse(igraph::V(graph)$name %in% top_nodes, igraph::V(graph)$name, ""),
            group = igraph::V(graph)$community,
            value = igraph::V(graph)$degree,
            title = paste0(
                "<b style='color:black;'>", igraph::V(graph)$name, "</b><br>",
                "<span style='color:black;'>연결: ", igraph::V(graph)$degree, "<br>",
                "고유벡터: ", round(igraph::V(graph)$eigenvector, 2), "<br>",
                "커뮤니티: ", igraph::V(graph)$community, "</span>"
            )
        )
        edges <- igraph::as_data_frame(graph, what = "edges")
        edges$correlation <- term_cor$correlation[match(paste(edges$from, edges$to), paste(term_cor$item1, term_cor$item2))]
        edges$width <- scales::rescale(edges$correlation, to = c(1, 8))
        
        edge_color_base <- "#5C5CFF"
        edges$color <- mapply(function(corr) {
          alpha_val <- scales::rescale(abs(corr), to = c(0.3, 1))
          scales::alpha(edge_color_base, alpha_val)
        }, edges$correlation)
        edges$title <- paste0(
          "<span style='color:black;'>상관관계: ", round(edges$correlation, 3),
          "<br>출발점: ", edges$from,
          "<br>도착점: ", edges$to, "</span>"
        )
        
        unique_communities <- sort(unique(nodes$group))
        community_map <- setNames(seq_along(unique_communities), unique_communities)
        nodes$group <- community_map[as.character(nodes$group)]
        
        n_communities <- length(unique(nodes$group))
        if (n_communities <= 8) {
          palette <- brewer.pal(n_communities, "Set2")
        } else {
          palette <- colorRampPalette(brewer.pal(8, "Set2"))(n_communities)
        }
        community_colors <- setNames(palette, as.character(seq_len(n_communities)))
        nodes$color <- community_colors[as.character(nodes$group)]
        
        legend_labels <- lapply(seq_len(n_communities), function(i) {
          community_size <- sum(nodes$group == i)
          list(label = paste0("커뮤니티 ", i, " (", community_size, ") "), color = community_colors[as.character(i)], shape = "dot")
        })
        
        plot <- visNetwork(nodes, edges) %>%
            visNodes(font = list(color = "black", size = node_label, vadjust = 0)) %>%
            visOptions(
                highlightNearest = list(
                    enabled = TRUE,
                    degree = 1,
                    hover = TRUE,
                    algorithm = "hierarchical"
                ), 
                nodesIdSelection = TRUE,
                manipulation = FALSE,
                selectedBy = list(
                    variable = "group",
                    multiple = FALSE,
                    style = "width: 150px; height: 26px;"
                )
            ) %>%
            visPhysics(
                solver = "barnesHut",
                barnesHut = list(
                    gravitationalConstant = -1500,
                    centralGravity = 0.4,
                    springLength = 100,
                    springConstant = 0.05,
                    avoidOverlap = 0.3 
                ),
                stabilization = list(enabled = TRUE, iterations = 1000)
            ) %>%
            visInteraction(
                hover = TRUE,
                tooltipDelay = 0,
                tooltipStay = 1000,
                zoomView = TRUE,
                dragView = TRUE
            ) %>%
            {if (showlegend) visLegend(., 
                addNodes = do.call(rbind, lapply(legend_labels, as.data.frame)),
                useGroups = FALSE,
                position = "right",
                width = 0.2,
                zoom = FALSE
            ) else .} %>%
            visLayout(randomSeed = ifelse(is.null(seed), 2025, seed))
        
        return(list(
            plot = plot,
            nodes = nodes,
            edges = edges,
            graph = graph,
            layout_df = layout_df
        ))
    }
    
    if (!is.null(doc_var) && length(docvar_levels) > 1) {
        plots_list <- dfm_td %>%
            dplyr::ungroup() %>%
            dplyr::group_by(!!rlang::sym(doc_var)) %>%
            dplyr::group_map(~ {
                group_level <- .y[[doc_var]]
                print(paste("Processing group level:", group_level))
                
                if (is.null(group_level)) {
                    stop("doc_var is missing or not found in the current group")
                }
                
                net <- build_network_plot(.x, group_level)
                if (!is.null(net)) {
                    net$vis %>% visNetwork::visLayout(
                        annotations = list(
                            list(
                                text = group_level,
                                x = 0.42,
                                xanchor = "center",
                                y = 0.98,
                                yanchor = "bottom",
                                yref = "paper",
                                showarrow = FALSE,
                                font = list(size = 19, color = "black", family = "Arial Black")
                            )
                        )
                    )
                } else {
                    NULL
                }
            })
        
        combined_plot <- plotly::subplot(plots_list, nrows = nrows, shareX = TRUE, shareY = TRUE,
                                         titleX = TRUE, titleY = TRUE)
        
        table_list <- lapply(docvar_levels, function(level) {
            print(paste("Generating table for level:", level))
            group_data <- dplyr::filter(dfm_td, !!rlang::sym(doc_var) == level)
            net <- build_network_plot(group_data)
            if (!is.null(net)) build_table(net) else NULL
        })
        
        return(list(
            plot = combined_plot,
            table = table_list %>% htmltools::tagList() %>% htmltools::browsable()
        ))
    } else {
        net <- build_network_plot(dfm_td)
        if (is.null(net)) {
            message("No network generated.")
            return(NULL)
        }
        return(list(
            plot = net$plot,
            table = build_table(net) %>% htmltools::browsable()
        ))
    }
}

file_info <- data.frame(filepath = "data/wos.xlsx")

wos <- TextAnalysisR::process_files(dataset_choice = "Upload Your File",
                                       file_info = file_info)

df_2009_earlier <- wos %>%
    filter(
        PY <= 2009 &
            (
                str_detect(AB, regex("learn.* disab.*", ignore_case = TRUE)) |
                    str_detect(DE, regex("learn.* disab.*", ignore_case = TRUE)) |
                    str_detect(TI, regex("learn.* disab.*", ignore_case = TRUE))
            )
    )

united_tbl_2009_earlier <- TextAnalysisR::unite_text_cols(df_2009_earlier, listed_vars = c("AB", "DE", "TI"))

tokens_2009_earlier <- TextAnalysisR::preprocess_texts(united_tbl_2009_earlier,
                                                     text_field = "united_texts",
                                                     min_char = 2,
                                                     remove_punct = TRUE,
                                                     remove_symbols = TRUE,
                                                     remove_numbers = TRUE,
                                                     remove_url = TRUE,
                                                     remove_separators = TRUE,
                                                     split_hyphens = TRUE,
                                                     split_tags = TRUE,
                                                     include_docvars = TRUE,
                                                     keep_acronyms = FALSE,
                                                     padding = FALSE,
                                                     verbose = FALSE)

custom_dict <- quanteda::dictionary(list(custom = c("learning disabilities", "single-case", "single-subject", "functional relation", "visual analysis")))

toks_compound_2009_earlier <- quanteda::tokens_compound(
    tokens_2009_earlier,
    pattern = custom_dict,
    concatenator = "_",
    valuetype = "glob",
    window = 0,
    case_insensitive = TRUE,
    join = TRUE,
    keep_unigrams = FALSE,
    verbose = TRUE
)

dfm_object_init_2009_earlier <- quanteda::dfm(toks_compound_2009_earlier)

stopwords <- stopwords::stopwords("en", source = "snowball")

toks_removed_2009_earlier <- quanteda::tokens_remove(toks_compound_2009_earlier, pattern = stopwords, verbose = FALSE)

dfm_init_2009_earlier <- quanteda::dfm(toks_removed_2009_earlier)

common_words <- c("study", "students", "research", "results")

toks_removed_common_2009_earlier <- quanteda::tokens_remove(toks_removed_2009_earlier, pattern = common_words, verbose = FALSE)

dfm_2009_earlier <- quanteda::dfm(toks_removed_common_2009_earlier)

# TextAnalysisR::plot_word_frequency(dfm_2009_earlier, n = 20)

word_network_2009_earlier <- word_correlation_network(
    dfm_2009_earlier,
    doc_var = NULL,
    common_term_n = 3,
    corr_n = 0.2,
    top_node_n = 25,
    node_label = 15,
    nrows = 1,
    height = 1500,
    width = 1500,
    pattern = "learn.*disab.*|single.*case|single.*subject|visual.*analy*|multi.*level|funtion.*relation|bayesian",
    showlegend = FALSE,
    seed = 2025
)

network_2009_earlier_plot <- word_network_2009_earlier$plot  
network_2009_earlier_table <- word_network_2009_earlier$table 

htmlwidgets::saveWidget(network_2009_earlier_plot, file = "figures/network_2009_earlier.html", selfcontained = TRUE)
```

-   [<i class="fas fa-project-diagram"></i>](figures/network_2009_earlier.html){.hover-effect
    style="color: #6D6D6D; text-decoration: none;"} 3번이상 언급, 최소
    0.2 상관관계

-   "학습장애" 가장 높은 연결중심성

-   "학습장애"와 "읽기" 0.56의 가장 높은 상관관계

![](figures/network_2009_earlier.png){fig-align="center" width="507"
height="420"}
:::

::: {.column width="40%"}
```{r, echo=FALSE}
network_2009_earlier_table
```
:::
:::::

## `2010년-2025년 학습장애 학생 단일대상 실험설계 동향`

::::: columns
::: {.column width="60%"}
```{r, eval=FALSE}
df_2010_later <- df %>%
  filter(
    PY >= 2010 &
    (
      str_detect(AB, regex("learn.* disab.*", ignore_case = TRUE)) |
      str_detect(DE, regex("learn.* disab.*", ignore_case = TRUE)) |
      str_detect(TI, regex("learn.* disab.*", ignore_case = TRUE))
    )
  )

united_tbl_2010_later <- TextAnalysisR::unite_text_cols(df_2010_later, listed_vars = c("AB", "DE", "TI"))

tokens_2010_later <- TextAnalysisR::preprocess_texts(united_tbl_2010_later,
                                          text_field = "united_texts",
                                          min_char = 2,
                                          remove_punct = TRUE,
                                          remove_symbols = TRUE,
                                          remove_numbers = TRUE,
                                          remove_url = TRUE,
                                          remove_separators = TRUE,
                                          split_hyphens = TRUE,
                                          split_tags = TRUE,
                                          include_docvars = TRUE,
                                          keep_acronyms = FALSE,
                                          padding = FALSE,
                                          verbose = FALSE)

custom_dict <- quanteda::dictionary(list(custom = c("learning disabilities", "single-case", "single-subject", "functional relation", "visual analysis")))

toks_compound_2010_later <- quanteda::tokens_compound(
  tokens_2010_later,
  pattern = custom_dict,
  concatenator = "_",
  valuetype = "glob",
  window = 0,
  case_insensitive = TRUE,
  join = TRUE,
  keep_unigrams = FALSE,
  verbose = TRUE
)

dfm_object_init_2010_later <- quanteda::dfm(toks_compound_2010_later)

stopwords <- stopwords::stopwords("en", source = "snowball")

toks_removed_2010_later <- quanteda::tokens_remove(toks_compound_2010_later, pattern = stopwords, verbose = FALSE)

dfm_init_2010_later <- quanteda::dfm(toks_removed_2010_later)

common_words <- c("study", "students", "research", "results")

toks_removed_common_2010_later <- quanteda::tokens_remove(toks_removed_2010_later, pattern = common_words, verbose = FALSE)

dfm_2010_later <- quanteda::dfm(toks_removed_common_2010_later)

# TextAnalysisR::plot_word_frequency(dfm_2010_later, n = 20)

word_network_2010_later <- word_correlation_network(
  dfm_2010_later,
  doc_var = NULL,
  common_term_n = 3,
  corr_n = 0.28,
  top_node_n = 25,
  node_label = 30,
  nrows = 1,
  height = 1000,
  width = 1500,
  pattern = "learn.*disab.*|single.*case|single.*subject|visual.*analy*|multi.*level|funtion.*relation|bayesian",
  showlegend = FALSE,
  seed = 2025
)

network_2010_later_plot <- word_network_2010_later$plot  
network_2010_later_table <- word_network_2010_later$table  

htmlwidgets::saveWidget(network_2010_later_plot, file = "figures/network_2010_later.html", selfcontained = TRUE)
```

-   [<i class="fas fa-project-diagram"></i>](figures/network_2010_later.html){.hover-effect
    style="color: #6D6D6D; text-decoration: none;"} 3번이상 언급, 최소
    0.28 상관관계
-   "다층" 가장 높은 연결중심성
-   "다층"과 "시각적 분석" 0.42의 높은 상관관계
-   "시각적 분석"과 "Tau" 0.34의 상관관계

![](figures/network_2010_later.png){fig-align="center" width="556"
height="367"}
:::

::: {.column width="40%"}
```{r, echo=FALSE}
network_2010_later_table
```
:::
:::::

## `시각적 분석을 통한 행동 변화 확인`

-   개별 학생(*N*=1) 또는 소집단을 대상으로 중재를 제공

-   행동의 예측, 검증, 재현 과정을 통하여 내적 타당도를 확인

-   그래프 데이터가 수집되어야 하며, 시각적인 분석이 이루어짐

-   연구설계에 따라서 기초선, 중재, 유지, 일반화 구간 등 설정

```{r, eval=FALSE}
AB <- read_csv("data/ABAB.csv", show_col_types = FALSE)

AB$Case <- paste0("학생 ", AB$Case, sep = "")

AB.plot <-  AB %>%
    ggplot(aes(Session, Outcome)) +
    geom_line(data = subset(AB, AB$Phase == "Baseline1"), aes(linetype='1'), linewidth = 0.5) +
    geom_line(data = subset(AB, AB$Phase == "Baseline1.Predict"), aes(linetype='2'), linewidth = 0.5) +
    geom_line(data = subset(AB, AB$Phase == "Intervention1"), aes(linetype='1'), linewidth = 0.5) +
    geom_line(data = subset(AB, AB$Phase == "Intervention1.Predict"), aes(linetype='2'), linewidth = 0.5) +
    geom_line(data = subset(AB, AB$Phase == "Baseline2"), aes(linetype='1'), linewidth = 0.5) +
    geom_line(data = subset(AB, AB$Phase == "Intervention2"), aes(linetype='1'), linewidth = 0.5) +
    geom_point(size = 2.5) +
    theme_minimal(base_size = 13) +
    theme(
        plot.title = element_text(face = "bold", size = 15),
        legend.position ="top",
        panel.grid.major = element_line(colour = "grey95", linewidth = 0.2),
        panel.grid.minor = element_blank(),
        legend.text = element_text(size = 13),
        legend.title = element_text(size = 13, hjust = 0.5),
        strip.text.x = element_text(color = "#3B3B3B", size = 13),
        axis.text.x = element_text(size = 13, color = "#3B3B3B"),
        axis.text.y = element_text(size = 13, color = "#3B3B3B"),
        axis.title = element_text(face = "bold", size = 13, color = "#3B3B3B")
    ) +
    labs(
        x = "회기",
        y = "바람직한 행동(%)"
    ) +
    guides(linetype="none") +
    geom_vline(aes(xintercept = 3.5), linetype = "longdash", linewidth = 0.3, color = "grey10") +
    geom_vline(aes(xintercept = 8.5), linetype = "longdash", linewidth = 0.3, color = "grey10") +
    geom_vline(aes(xintercept = 12.5), linetype = "longdash", linewidth = 0.3, color = "grey10") +
    annotate(geom = "text", x = 2, y = 95, label = "기초선", color = "#0000FF", fontface = 'bold', size = 5.5) +
    annotate(geom = "text", x = 6, y = 95, label = "중재", color = "#0000FF", fontface = 'bold', size = 5.5) +
    annotate(geom = "text", x = 10.5, y = 95, label = "기초선", color = "#0000FF", fontface = 'bold', size = 5.5) +
    annotate(geom = "text", x = 15, y = 95, label = "중재", color = "#0000FF", fontface = 'bold', size = 5.5) +
    annotate(geom = "text", x = 6, y = 25, label = "예측하기", color = 'red', fontface = 'bold', size = 5.5) +
    annotate(geom = "text", x = 10.5, y = 5, label = "검증하기", color = 'red', fontface = 'bold', size = 5.5) +
    annotate(geom = "text", x = 15, y = 75, label = "재현하기", color = 'red', fontface = 'bold', size = 5.5) +
    annotate("rect", xmin = 3.8, xmax = 8.3, ymin = 0, ymax = 20, alpha = .2) +
    annotate("rect", xmin = 8.8, xmax = 12.3, ymin = 60, ymax = 90, alpha = .2) 

AB_plot <- AB.plot %>% ggplotly(height = 400) %>% layout(dragmode = "select")
```

```{r, echo=FALSE}
AB_plot
```

::: {style="font-size: 0.8em; "}
(신미경, 2022) 자료
:::

## `다층모형을 통하여 종단자료 분석`

-   개인의 행동을 시간에 따라 반복적으로 측정

-   조각별 성장모형을 통하여 구간 간의 행동 변화를 측정

-   *t* 시점의 관측치는 이전 시점의 관측치와 관련있음 (자기상관계수)

-   패널조사 등의 종단 연구와 다르게 집중적이고 빈번하게 데이터를 측정

-   반복측정에서 가까운 시점 간의 상관계수가 먼 시점 간의 상관계수보다
    높음

[<i class="fas fa-code"></i>
Code](https://mshin77.github.io/multilevel-SCD/){.hover-effect
style="color: #6D6D6D; text-decoration: none;"}
     
::: {style="font-size: 0.8em; line-height: 1;"}
Shin, M., Hart, S. L., & Simmons, M. (2024). Meta-analysis of single-case design research: Application of multilevel modeling. *School Psychology, 39*(6), 625-635. <https://doi.org/10.1037/spq0000637>
:::


## `비연속 분할 회귀 모형`

-   각 구간마다 조건을 변화하며, 중재를 제공한 후에 학생의 수행 수준이
    즉각적으로 변화하고, 중재 구간에서 목표한 행동 방향으로 행동이
    증가하거나 감소할 것을 예상함(Center et al, 1985)

![](figures/piecewise.png){fig-align="center" width="662"}

::: {style="font-size: 0.8em; "}
(Wilbert, 2025)
:::

## `학습장애 학생 수학 중재 연구`

-   

    1.  `테크놀로지 보조 교수 및 교사의 의사소통 촉진`은 중학교 학습장애
        학생의 `분수 곱셈 시각화` 및 `문장제 문제풀이` 향상에 어떠한
        효과를 미치는가? (시각적 분석)

-   

    2.  `문장제 문제 질문 유형`(시각화 대 문제해결)은 `구간 간`(기초선
        대 중재, 중재 대 유지) 행동 변화에 어떠한 `조절 효과`를
        보이는가? (베이지안 다층 모형)

::: {style="font-size: 0.8em; line-height: 1;"}
Shin, M., & Park, J. (2024). Technology-assisted instruction with
teacher prompts on fraction multiplication word problems: A single-case
design with visual analysis and Bayesian multilevel modeling. *Assistive
Technology*. Advance online publication.
<https://doi.org/10.1080/10400435.2024.2415366>
:::

## `웹기반 분수 곱셈 온라인 교수`

[<i class="fas fa-mobile-alt"></i>
웹사이트](https://funfraction.org/){.hover-effect
style="color: #6D6D6D; text-decoration: none;"}

::: {.iframe-container style="width: 100%; max-width: 800px; height: 700px; margin: 0 auto;"}
<iframe src="https://funfraction.org/" style="width: 100%; height: 100%; border: none;">

</iframe>
:::

## `다중구성요소 테크놀로지 보조 수학 중재`

::::: columns
::: {.column width="50%"}
#### [근거기반 중재 구성 요소]{style="color: #0782ed"}

-   웹기반 수학 중재
-   스크립트 기반 교사 수학 의사소통 촉진
-   인지 및 메타인지 전략
-   비디오 모델링
-   분수 곱셈 문장제 문제해결력 향상
:::

::: {.column width="50%"}
#### [가상 조작물 활용]{style="color: #0782ed"}

-   상호작용적인 시각적 모형
-   마우스 혹은 스크린 터치를 통하여 조작 가능
-   다양한 시각적 모형 제공
-   즉각적인 피드백 제공
-   다양한 예시의 활용 및 생성
:::
:::::

## `연구방법`

::::: columns
::: {.column width="50%"}
-   미국 남동부 지역 중학교
-   리소스 수학 학급(매일 50분씩 수학 수업 받음)
-   특수교육 교사, 일대일 방식으로 중재
-   연구 참여 포함 기준: 6-8학년 재학, 수학학업성취도(주 시험)
    학교수준보다 미달, 수학개별교육프로그램 목표 가짐, 선별 검사 30%
    미만
:::

::: {.column width="50%"}
![](figures/학생.png){fig-align="center" width="546"}
:::
:::::

## `시각적 분석 연구결과`

[<i class="fas fa-code"></i>
Code](https://mshin77.github.io/tech-assisted/#Graphing){.hover-effect
style="color: #6D6D6D; text-decoration: none;"}

::::: columns
::: {.column width="60%"}
![](figures/그래프2.png){fig-align="center" width="662"}
:::

::: {.column width="40%"}
-   `대상자 간 중다간헐기초선 설계`는 중재와 목표 수학 행동 간
    `기능적 관계`가 있음을 보여주었음
-   중재를 통하여 기초선과 비교했을 때 `분수 곱셈` 시각화 및 문장제
    문제풀이에서 모두 향상함
-   `시각화`: 기초선 대 중재 Tau = 0.76 \~ 1.00, 중재 대 유지 Tau =
    -0.29 \~ 0.33
-   `문장제 문제풀이`: 기초선 대 중재 Tau = 1.00, 중재 대 유지 Tau =
    -0.71 \~ 0.10
:::
:::::

## `베이지안 다층 모형 연구결과`

$$
\begin{aligned}
\operatorname{logit}\left[\pi_{k i j l}(Y>k)\right] & =\ln \left(\frac{\pi\left(Y_{i j l}>k\right)}{\pi\left(Y_{i j l} \leq k\right)}\right) \\
& =-\alpha_k+\left(\beta_{0 j l}+\beta_{1 j l}\left(t-T_{1 j l}\right)\right. \\
& +\beta_{2 j l}\left(t>T_{2 j l}\right)+\beta_{3 j l}\left(t-T_{2 j l}\right) \\
& \times\left(t>T_{2 j l}\right)+\beta_{4 j l}\left(t>T_{3 j l}\right) \\
& \left.+\beta_{5 j l}\left(t-T_{3 j l}\right) \times\left(t>T_{3 j l}\right)\right),
\end{aligned}
$$

-   $\pi_{k i j l}=$ 절단점 $k$ 를 초과할 누적확률 (6점 척도 수학 점수)
-   $T_{1 j l}, T_{2 j l}, T_{3 j l}=$ 기초선, 중재, 유지 구간 시작점
-   $\left(t>T_{2 j l}\right),\left(t>T_{3 j l}\right)=$ 거짓(0) 또는
    참(1)
-   $\beta_{0 j l} \sim \beta_{5 j l}$: 기초선 대 중재, 중재 대 유지 수준 및 추세 변화
-   학습장애 학생들은 분수 곱셈 문장제 문제해결 과제에서 시각화
    문제에서보다 더 높은 유지 효과를 나타냈음 
- 수준(logit = 2.6) 및 추세(logit = 0.22) 변화로 이러한 중재 효과를 재확인

```{r, echo=FALSE}
save(AB_plot, df, dfm_2009_earlier, dfm_2010_later, network_2009_earlier_plot, network_2009_earlier_table, network_2010_later_plot, network_2010_later_table, year_plotly, file = "data/2025ksse_data.RData")
```
